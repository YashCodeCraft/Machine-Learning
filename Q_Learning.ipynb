{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5cXFMCiWnMU"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.zeros((16, 4), dtype = int))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30iOXG43TI8U",
        "outputId": "5d22ec8a-d30e-4068-df1d-d9cd85d3cdd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tot_states = 16\n",
        "tot_actions = 4\n",
        "tar_state = 15\n",
        "\n",
        "q_table = np.zeros((tot_states, tot_actions))\n",
        "q_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sd_4_ajLTVBY",
        "outputId": "a2e81fc2-6985-417c-dbef-78d895643fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the environment\n",
        "n_states = 16  # Number of states in the grid world\n",
        "n_actions = 4  # Number of possible actions (up, down, left, right)\n",
        "goal_state = 1  # Goal state\n",
        "\n",
        "# Initialize Q-table with zeros\n",
        "Q_table = np.zeros((n_states, n_actions))\n",
        "\n",
        "# Define parameters\n",
        "learning_rate = 0.75\n",
        "discount_factor = 0.92\n",
        "exploration_prob = 0.3\n",
        "epochs = 1000\n"
      ],
      "metadata": {
        "id": "kctjB4OUTfRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q-learning algorithm\n",
        "for epoch in range(epochs):\n",
        "    current_state = np.random.randint(0, n_states)  # Start from a random state\n",
        "\n",
        "    while current_state != goal_state:\n",
        "        # Choose action with epsilon-greedy strategy\n",
        "        if np.random.rand() < exploration_prob:\n",
        "            action = np.random.randint(0, n_actions)  # Explore\n",
        "        else:\n",
        "            action = np.argmax(Q_table[current_state])  # Exploit\n",
        "\n",
        "        # Simulate the environment (move to the next state)\n",
        "        # For simplicity, move to the next state\n",
        "        next_state = (current_state + 1) % n_states\n",
        "\n",
        "        # Define a simple reward function (1 if the goal state is reached, 0 otherwise)\n",
        "        reward = 1 if next_state == goal_state else 0\n",
        "\n",
        "        # Update Q-value using the Q-learning update rule\n",
        "        Q_table[current_state, action] += learning_rate * \\\n",
        "            (reward + discount_factor *\n",
        "             np.max(Q_table[next_state]) - Q_table[current_state, action])\n",
        "\n",
        "        current_state = next_state  # Move to the next state\n",
        "\n",
        "# After training, the Q-table represents the learned Q-values\n",
        "print(\"Learned Q-table:\")\n",
        "print(Q_table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7t381e9NYJXY",
        "outputId": "c4c577c8-6652-4411-e871-3a15b96421e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learned Q-table:\n",
            "[[1.         1.         1.         1.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.31119283 0.30997723 0.31117383 0.30633044]\n",
            " [0.33823058 0.33823243 0.33825308 0.338253  ]\n",
            " [0.36766639 0.36766639 0.36766637 0.36766639]\n",
            " [0.39963738 0.39963738 0.39963738 0.39963738]\n",
            " [0.43438845 0.43438845 0.43438845 0.43438845]\n",
            " [0.47216136 0.47216136 0.47216136 0.47216136]\n",
            " [0.51321887 0.51321887 0.51321887 0.51321887]\n",
            " [0.5578466  0.5578466  0.5578466  0.5578466 ]\n",
            " [0.606355   0.606355   0.606355   0.606355  ]\n",
            " [0.65908152 0.65908152 0.65908152 0.65908152]\n",
            " [0.71639296 0.71639296 0.71639296 0.71639296]\n",
            " [0.778688   0.778688   0.778688   0.778688  ]\n",
            " [0.8464     0.8464     0.8464     0.8464    ]\n",
            " [0.92       0.92       0.92       0.92      ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# n+=1 = n=n+1\n",
        "q_table[11, 3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FzihThdd6Rl",
        "outputId": "2273d2a7-c36a-432b-d9e1-b143523b7232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jbg-9wC2e3RP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}